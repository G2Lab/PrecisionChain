{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import binascii\n",
    "import argparse\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE\n",
    "import os\n",
    "import psutil\n",
    "import time\n",
    "import multiprocessing\n",
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "import ast\n",
    "import multiprocessing\n",
    "from gtfparse import read_gtf\n",
    "from io import BytesIO, StringIO\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "from scipy.spatial import distance\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "multichainLoc = ''\n",
    "chainName = 'test_chain'\n",
    "datadir = '/gpfs/commons/groups/gursoy_lab/aelhussein/blockchain/multichain'\n",
    "dataPath = '/gpfs/commons/groups/gursoy_lab/aelhussein/blockchain/code/16k_scalability/data/vcf/wgs'\n",
    "variantfile = 'all'\n",
    "metaFile = '/gpfs/commons/groups/gursoy_lab/aelhussein/blockchain/code/16k_scalability/data/mapping_vocab/metadata.csv'\n",
    "numberPeople = 100\n",
    "person = int(numberPeople)\n",
    "cpu = 1\n",
    "chromosomes = 4\n",
    "positions = '3416438'\n",
    "genotypes = '1|1'\n",
    "metadata = 'FreeBayes'\n",
    "annotation_path = '/gpfs/commons/groups/gursoy_lab/aelhussein/blockchain/code/16k_scalability/data/annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracted GTF attributes: ['gene_id', 'gene_type', 'gene_name']\n"
     ]
    }
   ],
   "source": [
    "geneFile, variantFile, chrom = '/gpfs/commons/groups/gursoy_lab/aelhussein/blockchain/code/16k_scalability/data/gtf/gtf_chr4.txt', '/gpfs/commons/groups/gursoy_lab/aelhussein/blockchain/code/16k_scalability/data/vcf/wgs/chr_4.vcf.gz', 4\n",
    "#read in gtf file using data\n",
    "df = read_gtf(geneFile, \n",
    "                usecols=['seqname','gene_id','feature','start','end', 'gene_type', 'gene_name','strand'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaFile = '/gpfs/commons/groups/gursoy_lab/aelhussein/blockchain/data/preprocessing/'\n",
    "sampleIDFile = '/gpfs/commons/groups/gursoy_lab/aelhussein/blockchain/code/16k_scalability/data/vcf/wgs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(pcaFile, sampleIDFile):\n",
    "    '''\n",
    "    Load sample principal components, reference loadings and sample ids\n",
    "    Input:\n",
    "        file paths for pca data and sample ids\n",
    "    '''\n",
    "    #Sample PCs\n",
    "    sample_pcs = pd.read_csv(f'{pcaFile}pca/samples_pcs.csv')\n",
    "    #Reference loadings\n",
    "    ref_v = pd.read_csv(f'{pcaFile}pca_ref/v_loadings.csv')\n",
    "    ref_center = pd.read_csv(f'{pcaFile}pca_ref/center_values.csv')\n",
    "    ref_scale = pd.read_csv(f'{pcaFile}pca_ref/scale_values.csv')\n",
    "    #Set sample IDs\n",
    "    command = f'bcftools query -l {sampleIDFile}/chr_1.vcf.gz'\n",
    "    items = subprocess.check_output(command.split())\n",
    "    samples = items.decode().split(\"\\n\")[:-1]\n",
    "    sample_pcs.index= samples\n",
    "    return sample_pcs, (ref_v, ref_center, ref_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publishSamplePC(chainName, multichainLoc, datadir, pcaFile, sampleIDFile):\n",
    "    '''\n",
    "    Insert samples principal components\n",
    "    Input:\n",
    "        file paths for pca data and sample ids\n",
    "    '''\n",
    "    sample_pcs, ref_data = loadData(pcaFile, sampleIDFile)\n",
    "    for i, row in sample_pcs.iterrows():\n",
    "        streamName = 'GWAS'\n",
    "        streamKeys = ['PCA', i]\n",
    "        streamValues ='{\"json\":'+row.to_json()+'}' #create JSON and remove brackets\n",
    "\n",
    "        publishCommand = [multichainLoc+'multichain-cli', \n",
    "            str('{}'.format(chainName)), \n",
    "            str('-datadir={}'.format(datadir)),\n",
    "            'publish',\n",
    "            str('{}'.format(streamName)), \n",
    "            str('[\"{}\", \"{}\"]'.format(streamKeys[0], streamKeys[1])),\n",
    "            str('{}'.format(streamValues))]\n",
    "        procPublish = subprocess.Popen(publishCommand, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        procPublish.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publishSamplePC(chainName, multichainLoc, datadir, pcaFile, sampleIDFile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSearch = '91646,82285,37633'\n",
    "kSearch = int('8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def querySamplePCA(chainName, datadir, sampleSearch, kSearch):\n",
    "    '''\n",
    "    Query PC's of samples on chain\n",
    "    Input:\n",
    "        sampleSearch - sampled ids to extract\n",
    "        kSearch - number of PCs to get\n",
    "    '''\n",
    "    #Extract data\n",
    "    queryCommand = 'multichain-cli {} -datadir={} liststreamkeyitems GWAS {}'.format(chainName, datadir, \"PCA\")\n",
    "    items = subprocess.check_output(queryCommand.split())\n",
    "    matches = json.loads(items, parse_int= int)\n",
    "    #Create DF\n",
    "    sample_pcs = [(match_['keys'][1], match_['data']['json']) for match_ in matches]\n",
    "    pc_df = pd.DataFrame.from_dict(dict(sample_pcs)).T\n",
    "    #Filter based on search\n",
    "    sampleSearch = sampleSearch.split(',')\n",
    "    kSearch = int(kSearch)\n",
    "    if sampleSearch != ['none']:\n",
    "        pc_df = pc_df.loc[sampleSearch]\n",
    "    if kSearch != ['all']:\n",
    "        pc_df = pc_df.iloc[:,:kSearch]\n",
    "    print(pc_df)\n",
    "    return pc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               V1          V2         V3         V4        V5        V6  \\\n",
      "91646 -111.040673 -182.611776 -14.214253 -46.936272 -6.919233  1.603086   \n",
      "82285 -110.464685 -185.844757 -17.063498 -46.617285 -8.039273  0.601743   \n",
      "37633 -109.987731 -185.830888 -13.367774 -47.066450 -7.891876  0.291234   \n",
      "\n",
      "              V7        V8  \n",
      "91646 -66.650671  5.665950  \n",
      "82285 -68.136585  7.958371  \n",
      "37633 -70.303100  7.115474  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91646</th>\n",
       "      <td>-111.040673</td>\n",
       "      <td>-182.611776</td>\n",
       "      <td>-14.214253</td>\n",
       "      <td>-46.936272</td>\n",
       "      <td>-6.919233</td>\n",
       "      <td>1.603086</td>\n",
       "      <td>-66.650671</td>\n",
       "      <td>5.665950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82285</th>\n",
       "      <td>-110.464685</td>\n",
       "      <td>-185.844757</td>\n",
       "      <td>-17.063498</td>\n",
       "      <td>-46.617285</td>\n",
       "      <td>-8.039273</td>\n",
       "      <td>0.601743</td>\n",
       "      <td>-68.136585</td>\n",
       "      <td>7.958371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37633</th>\n",
       "      <td>-109.987731</td>\n",
       "      <td>-185.830888</td>\n",
       "      <td>-13.367774</td>\n",
       "      <td>-47.066450</td>\n",
       "      <td>-7.891876</td>\n",
       "      <td>0.291234</td>\n",
       "      <td>-70.303100</td>\n",
       "      <td>7.115474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1          V2         V3         V4        V5        V6  \\\n",
       "91646 -111.040673 -182.611776 -14.214253 -46.936272 -6.919233  1.603086   \n",
       "82285 -110.464685 -185.844757 -17.063498 -46.617285 -8.039273  0.601743   \n",
       "37633 -109.987731 -185.830888 -13.367774 -47.066450 -7.891876  0.291234   \n",
       "\n",
       "              V7        V8  \n",
       "91646 -66.650671  5.665950  \n",
       "82285 -68.136585  7.958371  \n",
       "37633 -70.303100  7.115474  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "querySamplePCA(chainName, datadir, sampleSearch, kSearch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relatedness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatedFile = '/gpfs/commons/groups/gursoy_lab/aelhussein/blockchain/data/preprocessing/relatedness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryCommand = f\"bcftools query -l {relatedFile}/merged.vcf.gz\"\n",
    "#Load genotypes\n",
    "items = subprocess.check_output(queryCommand, shell=True)\n",
    "sampleids = items.decode().split('\\n')\n",
    "sampleids = sampleids[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelatednessSNP(sampleids, relatedFile):\n",
    "    '''\n",
    "    Extract the related snps used by GRAF\n",
    "    Input:\n",
    "        sampleids - list of sampleids to insert\n",
    "        relatedFile - location of the vcf file with snps\n",
    "    '''\n",
    "    #SNPS\n",
    "    gt_final = {}\n",
    "    #sampleids = sampleids.split(',')\n",
    "    for sampleid in sampleids:\n",
    "        queryCommand = f\"bcftools query -f '[%GT]\\\\n' -s {sampleid} {relatedFile}/merged.vcf.gz\"\n",
    "        #Load genotypes\n",
    "        process = subprocess.Popen(queryCommand, shell=True, stdout=subprocess.PIPE)\n",
    "        gt = []\n",
    "        while True:\n",
    "            line = process.stdout.readline().decode().strip()\n",
    "            if not line:\n",
    "                break\n",
    "            gt.append(line)\n",
    "\n",
    "        process.wait()\n",
    "\n",
    "        gt_mapper = {'0|0':0, '0|1':1, '1|0':1, '1|1':2}\n",
    "        #Update gt\n",
    "        modified_gt = []\n",
    "        for item in gt:\n",
    "            x, y = item.split('|')\n",
    "            x = min(int(x), 1)\n",
    "            y = min(int(y), 1)\n",
    "            modified_gt.append(f'{x}|{y}')\n",
    "        #Create final list per sample\n",
    "        gt_final[sampleid] = [gt_mapper[c] for c in modified_gt]\n",
    "\n",
    "    #AF\n",
    "    queryCommand = f\"bcftools query -f '%AF\\n'  {relatedFile}/merged.vcf.gz\"\n",
    "    #Load AF's\n",
    "    process = subprocess.Popen(queryCommand, shell=True, stdout=subprocess.PIPE)\n",
    "    af = []\n",
    "    while True:\n",
    "        line = process.stdout.readline().decode().strip()\n",
    "        if not line:\n",
    "            break\n",
    "        af.append(line)\n",
    "    process.wait()\n",
    "    af = [a[:4] for a in af]\n",
    "    return gt_final, af\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_final, af = getRelatednessSNP(sampleids, relatedFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publishRelatednessSNP(chainName, datadir, multichainLoc, sampleids, relatedFile):\n",
    "    '''\n",
    "    Publish the related snp gentoypes per sample onto the chain\n",
    "    Input:\n",
    "        sampleids - list of sampleids to insert\n",
    "        relatedFile - location of the vcf file with snps\n",
    "    '''\n",
    "    gt_final, af = getRelatednessSNP(sampleids, relatedFile)\n",
    "    #SNPs\n",
    "    for sample in gt_final:\n",
    "        streamName = 'GWAS'\n",
    "        streamKeys = ['Relatedness', sample]\n",
    "        streamValues ='{\"json\":'+json.dumps(gt_final[sample])+'}' #create JSON and remove brackets\n",
    "        publishCommand = [multichainLoc+'multichain-cli', \n",
    "            str('{}'.format(chainName)), \n",
    "            str('-datadir={}'.format(datadir)),\n",
    "            'publish',\n",
    "            str('{}'.format(streamName)), \n",
    "            str('[\"{}\",\"{}\"]'.format(streamKeys[0], streamKeys[1])),\n",
    "            str('{}'.format(streamValues))]\n",
    "        procPublish = subprocess.Popen(publishCommand, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        procPublish.wait()\n",
    "\n",
    "    #AF\n",
    "    streamName = 'GWAS'\n",
    "    streamKeys = ['Relatedness', 'AF']\n",
    "    streamValues ='{\"json\":'+json.dumps(af)+'}' #create JSON and remove brackets\n",
    "    publishCommand = [multichainLoc+'multichain-cli', \n",
    "        str('{}'.format(chainName)), \n",
    "        str('-datadir={}'.format(datadir)),\n",
    "        'publish',\n",
    "        str('{}'.format(streamName)), \n",
    "        str('[\"{}\",\"{}\"]'.format(streamKeys[0], streamKeys[1])),\n",
    "        str('{}'.format(streamValues))]\n",
    "    procPublish = subprocess.Popen(publishCommand, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "publishRelatednessSNP(chainName, datadir, multichainLoc, sampleids, relatedFile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def querySampleRelatedness(chainName, datadir, sampleSearch):\n",
    "    '''\n",
    "    Query relatedness snps from chain\n",
    "    Input:\n",
    "        sampleSearch - sampled ids to extract\n",
    "    '''\n",
    "    #Extract data\n",
    "    queryCommand = 'multichain-cli {} -datadir={} liststreamkeyitems GWAS {}'.format(chainName, datadir, 'Relatedness')\n",
    "    items = subprocess.check_output(queryCommand.split())\n",
    "    matches = json.loads(items, parse_int= int)\n",
    "    #Create DF\n",
    "    sample_snps = [(match_['keys'][1], match_['data']['json']) for match_ in matches if match_['keys'][1].upper() != 'AF' ]\n",
    "    rl_df = pd.DataFrame.from_dict(dict(sample_snps)).T\n",
    "    #Filter based on search\n",
    "    sampleSearch = sampleSearch.split(',')\n",
    "    if sampleSearch != ['none']:\n",
    "        rl_df = rl_df.loc[sampleSearch]\n",
    "\n",
    "    #AF\n",
    "    queryCommand = 'multichain-cli {} -datadir={} liststreamkeyitems GWAS {}'.format(chainName, datadir, 'AF')\n",
    "    items = subprocess.check_output(queryCommand.split())\n",
    "    matches = json.loads(items, parse_int= int)\n",
    "    txid = matches[0]['data']['txid']\n",
    "    queryCommand = 'multichain-cli {} -datadir={} gettxoutdata {} 0'.format(chainName, datadir, txid)\n",
    "    items = subprocess.check_output(queryCommand.split())\n",
    "    matches = json.loads(items, parse_int= int)['json']\n",
    "    af = [float(match_) for match_ in matches]\n",
    "    return rl_df, af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_df, af = querySampleRelatedness(chainName, datadir, sampleSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def calculate_mismatch(df):\n",
    "    n = df.shape[0] \n",
    "    agmr_matrix = np.zeros((n, n)) \n",
    "    hgmr_matrix = np.zeros((n, n)) \n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n): \n",
    "            x = df.iloc[i]  \n",
    "            y = df.iloc[j]  \n",
    "            \n",
    "            # AGMR: percentage of SNPs on which the two genotypes are not identical\n",
    "            agmr = np.mean(x != y)\n",
    "            agmr_matrix[i, j] = agmr\n",
    "            agmr_matrix[j, i] = agmr  \n",
    "            \n",
    "            # HGMR: genotype mismatch rate when only the SNPs with homozygous calls for both samples are considered\n",
    "            homozygous_indices = (x % 2 == 0) & (y % 2 == 0)  \n",
    "            hgmr = np.mean(x[homozygous_indices] != y[homozygous_indices]) if np.sum(homozygous_indices) > 0 else 0\n",
    "            hgmr_matrix[i, j] = hgmr\n",
    "            hgmr_matrix[j, i] = hgmr \n",
    "\n",
    "    \n",
    "    agmr_df = pd.DataFrame(agmr_matrix, index=df.index, columns=df.index)\n",
    "    hgmr_df = pd.DataFrame(hgmr_matrix, index=df.index, columns=df.index)\n",
    "\n",
    "    return agmr_df, hgmr_df\n",
    "\n",
    "def determine_relationships(agmr_df, hgmr_df, relationship_parameters):\n",
    "    relationships = pd.DataFrame(index=agmr_df.index, columns=agmr_df.columns)\n",
    "    \n",
    "    for i in agmr_df.index:\n",
    "        for j in agmr_df.columns:\n",
    "            agmr = agmr_df.loc[i, j]\n",
    "            hgmr = hgmr_df.loc[i, j]\n",
    "\n",
    "            max_likelihood = -np.inf\n",
    "            max_rel = None\n",
    "            for rel, params in relationship_parameters.items():\n",
    "                likelihood = multivariate_normal(mean=params['mean'], cov=params['cov']).pdf([agmr, hgmr])\n",
    "                if likelihood > max_likelihood:\n",
    "                    max_likelihood = likelihood\n",
    "                    max_rel = rel\n",
    "            relationships.loc[i, j] = max_rel\n",
    "    return relationships\n",
    "\n",
    "def assess_kinship(rl_df):\n",
    "    relationship_parameters = {\n",
    "        'ID': {'mean': [0.0, 0.0], 'cov': [[0.01**2, 0.01*0.38*0.317], [0.01*0.38*0.317, 0.38**2]]},\n",
    "        'PO': {'mean': [0.04, 0.02], 'cov': [[0.07**2, 0.07*1.47*0.104], [ 0.07*1.47*0.104, 1.47**2]]},\n",
    "        'FS': {'mean': [0.36, 0.1], 'cov': [[1.02**2,  1.02*2.32*0.784], [1.02*2.32*0.784, 2.32**2]]},\n",
    "        'D2': {'mean': [0.40, 0.15], 'cov': [[1.35**2, 1.35*2.32*0.784], [0, 1.10**2]]},\n",
    "        'D3': {'mean': [0.44, 0.19], 'cov': [[1.35**2, 1.35*0.96*0.830], [1.35*0.96*0.830, 0.96**2]]},\n",
    "        'UR': {'mean': [0.54, 0.22], 'cov': [[1.35**2, 1.35*0.96*0.830], [1.35*0.96*0.830, 0.96**2]]}\n",
    "    }\n",
    "    agmr_df, hgmr_df  = calculate_mismatch(rl_df)\n",
    "    relationships = determine_relationships(agmr_df, hgmr_df, relationship_parameters)\n",
    "    return relationships\n",
    "\n",
    "def queryKinship(chainName, datadir, sampleSearch):\n",
    "    rl_df, af = querySampleRelatedness(chainName, datadir, sampleSearch)\n",
    "    relationships = assess_kinship(rl_df)\n",
    "    print(relationships)\n",
    "    return relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        HG00108 HG00109 HG00110\n",
      "HG00108      ID      UR      UR\n",
      "HG00109      UR      ID      UR\n",
      "HG00110      UR      UR      ID\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HG00108</th>\n",
       "      <th>HG00109</th>\n",
       "      <th>HG00110</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HG00108</th>\n",
       "      <td>ID</td>\n",
       "      <td>UR</td>\n",
       "      <td>UR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00109</th>\n",
       "      <td>UR</td>\n",
       "      <td>ID</td>\n",
       "      <td>UR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00110</th>\n",
       "      <td>UR</td>\n",
       "      <td>UR</td>\n",
       "      <td>ID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        HG00108 HG00109 HG00110\n",
       "HG00108      ID      UR      UR\n",
       "HG00109      UR      ID      UR\n",
       "HG00110      UR      UR      ID"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queryKinship(chainName, datadir, sampleSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kinship(df, allele_frequencies):\n",
    "    allele_frequencies = np.array(allele_frequencies)\n",
    "    genotypes = df.values / 2\n",
    "    p = allele_frequencies + 1e-2\n",
    "    q = 1 - allele_frequencies\n",
    "    def kinship(x, y):\n",
    "        kinship_coefficient = np.mean((x - 2*p)*(y-2*p) / (2*p*q))\n",
    "        return kinship_coefficient\n",
    "    pairwise_kinship = distance.pdist(genotypes, kinship)\n",
    "    square_kinship = distance.squareform(pairwise_kinship)\n",
    "    kinship_df = pd.DataFrame(square_kinship, index=df.index, columns=df.index)\n",
    "    #as squareform assumes 0 and not 1 for diagonal distance\n",
    "    np.fill_diagonal(kinship_df.values, 1)\n",
    "    return kinship_df.applymap(lambda x: round(x, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractRelatedSampled(chainName, datadir, sampleSearch):\n",
    "    #Calculate relatedness\n",
    "    rl_df, af = querySampleRelatedness(chainName, datadir, sampleSearch)\n",
    "    kinship = calculate_kinship(rl_df, af)\n",
    "    #Identify related samples\n",
    "    upper_triangular = np.triu(kinship.values, k=1)\n",
    "    row_indices, col_indices = np.where(upper_triangular > 0.65)\n",
    "    row_names = kinship.index[row_indices]\n",
    "    col_names = kinship.columns[col_indices]\n",
    "    related_samples = pd.DataFrame({'Sample_1': row_names, 'Sample_2': col_names})\n",
    "    print(rl_df, kinship, related_samples)\n",
    "    return rl_df, kinship, related_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0     1     2     3     4     5     6     7     8     9     ...  \\\n",
      "HG00108     0     0     1     0     2     0     1     1     2     0  ...   \n",
      "HG00109     0     0     0     1     0     0     1     2     1     0  ...   \n",
      "HG00110     1     0     1     1     2     0     0     2     0     1  ...   \n",
      "\n",
      "         9940  9941  9942  9943  9944  9945  9946  9947  9948  9949  \n",
      "HG00108     1     1     0     2     2     0     1     0     1     0  \n",
      "HG00109     1     0     0     2     2     0     0     2     1     0  \n",
      "HG00110     2     2     0     1     2     0     0     0     1     0  \n",
      "\n",
      "[3 rows x 9950 columns]          HG00108  HG00109  HG00110\n",
      "HG00108    1.000    0.628    0.636\n",
      "HG00109    0.628    1.000    0.631\n",
      "HG00110    0.636    0.631    1.000 Empty DataFrame\n",
      "Columns: [Sample_1, Sample_2]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "rl_df, kinship, related_samples = extractRelatedSampled(chainName, datadir, sampleSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HG00108</th>\n",
       "      <th>HG00109</th>\n",
       "      <th>HG00110</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HG00108</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00109</th>\n",
       "      <td>0.628</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00110</th>\n",
       "      <td>0.636</td>\n",
       "      <td>0.631</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HG00108  HG00109  HG00110\n",
       "HG00108    1.000    0.628    0.636\n",
       "HG00109    0.628    1.000    0.631\n",
       "HG00110    0.636    0.631    1.000"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kinship"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
